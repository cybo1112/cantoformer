{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from google.cloud import storage\n",
    "import tokenizers\n",
    "from transformers import BertTokenizer\n",
    "from tokenizers import BertWordPieceTokenizer\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "from torch.utils.data.sampler import RandomSampler\n",
    "import numpy as np\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18746072"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_length = 128\n",
    "accum_multipler = 1\n",
    "batch_size = 128\n",
    "epochs = 2\n",
    "warmup_ratio = 0.06\n",
    "lr = 5e-4\n",
    "\n",
    "data_size = os.stat(\"/mnt/d/data_masked_%s\"%seq_length).st_size // batch_size\n",
    "\n",
    "num_batches = -int(-data_size // batch_size) \n",
    "tot_num_steps   = -int(-data_size / batch_size / accum_multipler)  * epochs\n",
    "warmup_steps = int(tot_num_steps * warmup_ratio)\n",
    "data_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JUST TRY\n",
    "# Test Speed:  1.1862 steps /s  :  / bs128 / accum 1 /\n",
    "\n",
    "data_size = data_size // 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51243.84"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "12 * 3600 * 1.1862 # steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3279552.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "51243 * 128 / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size = 3279552"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_size:       3279552\n",
      "seq_length:      128\n",
      "lr:              0.0005\n",
      "epochs:          2\n",
      "tot_num_steps:   292906\n",
      "warmup_steps:    17574\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('data_size:      ', data_size)\n",
    "print('seq_length:     ', seq_length)\n",
    "print('lr:             ', lr)\n",
    "print('epochs:         ', epochs)\n",
    "print('tot_num_steps:  ', tot_num_steps)\n",
    "print('warmup_steps:   ', warmup_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: Tesla V100-SXM2-16GB\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():      \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('GPU:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print('CPU')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertWordPieceTokenizer(vocab_file = 'tokenizer/vocab.txt')\n",
    "tokenizer.add_special_tokens([\"<nl>\"])\n",
    "tokenizer.enable_truncation(max_length=seq_length)\n",
    "tokenizer.enable_padding(length=seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_original_fn = \"/mnt/d/data_original_%s\"%seq_length\n",
    "data_masked_fn   = \"/mnt/d/data_masked_%s\"%seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "i = random.randint(0, 100000)\n",
    "with open(data_original_fn, \"rb\") as f:\n",
    "    data = torch.tensor(np.fromfile(f,dtype=np.int32, count=seq_length, offset=seq_length*i*4))\n",
    "    \n",
    "with open(data_masked_fn, \"rb\") as f:\n",
    "    data_masked = torch.tensor(np.fromfile(f,dtype=np.int32, count=seq_length, offset=seq_length*i*4))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] the full . she was watching him and he grinned at her . ‘ stop \u001b[31mfishing\u001b[0m for compliment ##s . ’ <nl> melan ##ie grinned back , her head on one side . ‘ so \u001b[31m,\u001b[0m what about you and fi ##zz beau ##mont then ? ’ <nl> it was his turn to hesitate . ‘ what \u001b[31mdo\u001b[0m you \u001b[31mmean\u001b[0m ? ’ <nl> she threw him a look full of misc ##hi ##ef \u001b[31m.\u001b[0m ‘ i asked her if \u001b[31myou\u001b[0m \u001b[31m’\u001b[0m d had \u001b[31ma\u001b[0m row or something . ’ <nl> ‘ \u001b[31mthat\u001b[0m \u001b[31mwas\u001b[0m very rude of you . ’ <nl> ‘ probably \u001b[31m.\u001b[0m but i wanted to know . ’ <nl> ‘ and what did she say \u001b[31m?\u001b[0m ’ <nl> melan ##ie ’ s eyes gle [SEP] \n",
      "\n",
      "[CLS] the full . she was watching him and he grinned at her . ‘ stop \u001b[34mfishing\u001b[0m for compliment ##s . ’ <nl> melan ##ie grinned back , her head on one side . ‘ so \u001b[34m,\u001b[0m what about you and fi ##zz beau ##mont then ? ’ <nl> it was his turn to hesitate . ‘ what \u001b[34mdo\u001b[0m you \u001b[34mmean\u001b[0m ? ’ <nl> she threw him a look full of misc ##hi ##ef \u001b[34m.\u001b[0m ‘ i asked her if \u001b[34myou\u001b[0m \u001b[34m’\u001b[0m d had \u001b[34ma\u001b[0m row or something . ’ <nl> ‘ \u001b[34mthat\u001b[0m \u001b[34mwas\u001b[0m very rude of you . ’ <nl> ‘ probably \u001b[34m.\u001b[0m but i wanted to know . ’ <nl> ‘ and what did she say \u001b[34m?\u001b[0m ’ <nl> melan ##ie ’ s eyes gle [SEP] \n",
      "\n",
      "[CLS] the full . she was watching him and he grinned at her . ‘ stop \u001b[31m[MASK]\u001b[0m for compliment ##s . ’ <nl> melan ##ie grinned back , her head on one side . ‘ so \u001b[31m[MASK]\u001b[0m what about you and fi ##zz beau ##mont then ? ’ <nl> it was his turn to hesitate . ‘ what \u001b[31m[MASK]\u001b[0m you \u001b[31m[MASK]\u001b[0m ? ’ <nl> she threw him a look full of misc ##hi ##ef \u001b[31m[MASK]\u001b[0m ‘ i asked her if \u001b[31m[MASK]\u001b[0m \u001b[31m##usion\u001b[0m d had \u001b[31m[MASK]\u001b[0m row or something . ’ <nl> ‘ \u001b[31m[MASK]\u001b[0m \u001b[31m[MASK]\u001b[0m very rude of you . ’ <nl> ‘ probably \u001b[31m[MASK]\u001b[0m but i wanted to know . ’ <nl> ‘ and what did she say \u001b[31m[MASK]\u001b[0m ’ <nl> melan ##ie ’ s eyes gle [SEP] "
     ]
    }
   ],
   "source": [
    "from termcolor import colored\n",
    "tensor = torch.zeros(())\n",
    "labels = tensor.new_full(data.shape, -100).int()\n",
    "labels[data!=data_masked] = data[data!=data_masked]\n",
    "\n",
    "attention_mask = torch.where(data!=0, torch.ones_like(data), torch.zeros_like(data))\n",
    "\n",
    "for id, label in zip(data, labels):\n",
    "    token = tokenizer.id_to_token(id)\n",
    "    if label >= 0:\n",
    "        token = colored(token,'red')\n",
    "    print(token, end=\" \")\n",
    "print()\n",
    "print()\n",
    "\n",
    "for id, label in zip(data, labels):\n",
    "    if not id:\n",
    "        continue\n",
    "    token = tokenizer.id_to_token(id)\n",
    "    if label >= 0:\n",
    "        token = colored(tokenizer.id_to_token(label), 'blue')\n",
    "    print(token, end=\" \")\n",
    "print()\n",
    "print()\n",
    "for id, label in zip(data_masked, labels):\n",
    "    if not id:\n",
    "        continue\n",
    "    token = tokenizer.id_to_token(id)\n",
    "    if label >= 0:\n",
    "        token = colored(token,'red')\n",
    "    print(token, end=\" \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class textDataset(Dataset):\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "    def __getitem__(self,i):\n",
    "        with open(data_original_fn, \"rb\") as f:\n",
    "            data = torch.tensor(np.fromfile(f,dtype=np.int32, count=seq_length, offset=seq_length*i*4))\n",
    "\n",
    "        with open(data_masked_fn, \"rb\") as f:\n",
    "            data_masked = torch.tensor(np.fromfile(f,dtype=np.int32, count=seq_length, offset=seq_length*i*4))\n",
    "\n",
    "        tensor = torch.zeros(())\n",
    "        labels = tensor.new_full(data.shape, -100).int()\n",
    "        labels[data!=data_masked] = data[data!=data_masked]\n",
    "        \n",
    "        attention_mask = torch.where(data!=0, torch.ones_like(data), torch.zeros_like(data))\n",
    "        \n",
    "        return data_masked.long(), labels.long(), attention_mask.long(), data.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual batch size: 128\n",
      "Batch size per GPU per pass: 16\n"
     ]
    }
   ],
   "source": [
    "dataset = textDataset(data_size)\n",
    "dataloader = DataLoader(dataset, batch_size = batch_size, shuffle=True)\n",
    "\n",
    "print('Actual batch size:', batch_size * accum_multipler)\n",
    "\n",
    "print('Batch size per GPU per pass:', batch_size // torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom transformers import ElectraForMaskedLM, ElectraForPreTraining\\nfrom transformers import ElectraConfig\\nimport torch.nn as nn\\n\\ngenerator_config = ElectraConfig(\\n    vocab_size=50000,\\n    hidden_size = 64,\\n    intermediate_size = 128,\\n    num_attention_heads = 1\\n)\\ndiscriminator_config = ElectraConfig(\\n    vocab_size=50000\\n)\\n\\ngenerator = nn.DataParallel(ElectraForMaskedLM(config=generator_config))\\ngenerator.to(device)\\ndiscriminator = nn.DataParallel(ElectraForPreTraining(config=discriminator_config))\\ndiscriminator.to(device)\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from transformers import ElectraForMaskedLM, ElectraForPreTraining\n",
    "from transformers import ElectraConfig\n",
    "import torch.nn as nn\n",
    "\n",
    "generator_config = ElectraConfig(\n",
    "    vocab_size=50000,\n",
    "    hidden_size = 64,\n",
    "    intermediate_size = 128,\n",
    "    num_attention_heads = 1\n",
    ")\n",
    "discriminator_config = ElectraConfig(\n",
    "    vocab_size=50000\n",
    ")\n",
    "\n",
    "generator = nn.DataParallel(ElectraForMaskedLM(config=generator_config))\n",
    "generator.to(device)\n",
    "discriminator = nn.DataParallel(ElectraForPreTraining(config=discriminator_config))\n",
    "discriminator.to(device)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): ElectraForPreTraining(\n",
       "    (electra): ElectraModel(\n",
       "      (embeddings): ElectraEmbeddings(\n",
       "        (word_embeddings): Embedding(50000, 128, padding_idx=0)\n",
       "        (position_embeddings): Embedding(128, 128)\n",
       "        (token_type_embeddings): Embedding(2, 128)\n",
       "        (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (embeddings_project): Linear(in_features=128, out_features=256, bias=True)\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (3): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (4): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (5): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (6): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (7): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (8): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (9): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (10): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (11): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (discriminator_predictions): ElectraDiscriminatorPredictions(\n",
       "      (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (dense_prediction): Linear(in_features=256, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import ElectraForMaskedLM, ElectraForPreTraining\n",
    "from transformers import ElectraConfig\n",
    "import torch.nn as nn\n",
    "'''\n",
    "        vocab_size=30522,\n",
    "        embedding_size=128,\n",
    "        hidden_size=256,\n",
    "        num_hidden_layers=12,\n",
    "        num_attention_heads=4,\n",
    "        intermediate_size=1024,\n",
    "        hidden_act=\"gelu\",\n",
    "        hidden_dropout_prob=0.1,\n",
    "        attention_probs_dropout_prob=0.1,\n",
    "        max_position_embeddings=512,\n",
    "        type_vocab_size=2,\n",
    "        initializer_range=0.02,\n",
    "        layer_norm_eps=1e-12,\n",
    "        pad_token_id=0,\n",
    "\n",
    "'''\n",
    "\n",
    "'''\n",
    "sequence length: 512 -> 128\n",
    "\n",
    "batch size: 256 -> 128\n",
    "\n",
    "model hidden dimension: 768 -> 256\n",
    "\n",
    "embeddings: 768 -> 128\n",
    "'''\n",
    "generator_config = ElectraConfig(\n",
    "    max_position_embeddings=seq_length,\n",
    "    num_hidden_layers=12,\n",
    "    vocab_size=50000,\n",
    "    embedding_size=128,\n",
    "    hidden_size = 64,\n",
    "    intermediate_size = 256,\n",
    "    num_attention_heads=1,\n",
    ")\n",
    "discriminator_config = ElectraConfig(\n",
    "    max_position_embeddings=seq_length,\n",
    "    num_hidden_layers=12,\n",
    "    vocab_size=50000,\n",
    "    embedding_size=128,\n",
    "    hidden_size=256,\n",
    "    intermediate_size=1024,\n",
    "    num_attention_heads=4,\n",
    ")\n",
    "\n",
    "generator = nn.DataParallel(ElectraForMaskedLM(config=generator_config))\n",
    "generator.to(device)\n",
    "discriminator = nn.DataParallel(ElectraForPreTraining(config=discriminator_config))\n",
    "discriminator.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.module.electra.embeddings = generator.module.electra.embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\ntotal_steps seems wrong\\n\\nfrom transformers import get_linear_schedule_with_warmup\\nfrom transformers import AdamW\\ngenerator_optimizer = AdamW(generator.parameters(), betas=(0.9, 0.999), lr = lr, weight_decay=0.01)\\ndiscriminator_optimizer = AdamW(discriminator.parameters(), betas=(0.9, 0.999), lr = lr, weight_decay=0.01)\\n\\n\\ntotal_steps = len(dataloader) * epochs\\ngenerator_scheduler = get_linear_schedule_with_warmup(generator_optimizer, \\n                                            num_warmup_steps = warmup_steps,\\n                                            num_training_steps = total_steps)\\ndiscriminator_scheduler = get_linear_schedule_with_warmup(discriminator_optimizer, \\n                                            num_warmup_steps = warmup_steps,\\n                                            num_training_steps = total_steps)\\n                                            \\n                                            \\n                                            '"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "total_steps seems wrong\n",
    "\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from transformers import AdamW\n",
    "generator_optimizer = AdamW(generator.parameters(), betas=(0.9, 0.999), lr = lr, weight_decay=0.01)\n",
    "discriminator_optimizer = AdamW(discriminator.parameters(), betas=(0.9, 0.999), lr = lr, weight_decay=0.01)\n",
    "\n",
    "\n",
    "total_steps = len(dataloader) * epochs\n",
    "generator_scheduler = get_linear_schedule_with_warmup(generator_optimizer, \n",
    "                                            num_warmup_steps = warmup_steps,\n",
    "                                            num_training_steps = total_steps)\n",
    "discriminator_scheduler = get_linear_schedule_with_warmup(discriminator_optimizer, \n",
    "                                            num_warmup_steps = warmup_steps,\n",
    "                                            num_training_steps = total_steps)\n",
    "                                            \n",
    "                                            \n",
    "                                            '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "from transformers import AdamW\n",
    "generator_optimizer = AdamW(generator.parameters(), betas=(0.9, 0.999), lr = lr, weight_decay=0.01)\n",
    "discriminator_optimizer = AdamW(discriminator.parameters(), betas=(0.9, 0.999), lr = lr, weight_decay=0.01)\n",
    "\n",
    "total_steps = len(dataloader) * epochs\n",
    "generator_scheduler = get_linear_schedule_with_warmup(generator_optimizer, \n",
    "                                            num_warmup_steps = warmup_steps,\n",
    "                                            num_training_steps = tot_num_steps)\n",
    "discriminator_scheduler = get_linear_schedule_with_warmup(discriminator_optimizer, \n",
    "                                            num_warmup_steps = warmup_steps,\n",
    "                                            num_training_steps = tot_num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 2 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   200  of  25,622.    Elapsed: 0:03:17.    Generator Loss: 54.284.    Discriminator Loss: 2.914.\n",
      "  Batch   400  of  25,622.    Elapsed: 0:06:02.    Generator Loss: 52.188.    Discriminator Loss: 1.462.\n",
      "  Batch   600  of  25,622.    Elapsed: 0:08:48.    Generator Loss: 48.621.    Discriminator Loss: 0.640.\n",
      "  Batch   800  of  25,622.    Elapsed: 0:11:35.    Generator Loss: 44.140.    Discriminator Loss: 0.409.\n",
      "  Batch 1,000  of  25,622.    Elapsed: 0:14:24.    Generator Loss: 40.509.    Discriminator Loss: 0.550.\n",
      "  Batch 1,200  of  25,622.    Elapsed: 0:17:08.    Generator Loss: 38.512.    Discriminator Loss: 0.437.\n",
      "  Batch 1,400  of  25,622.    Elapsed: 0:19:54.    Generator Loss: 37.989.    Discriminator Loss: 0.432.\n",
      "  Batch 1,600  of  25,622.    Elapsed: 0:22:44.    Generator Loss: 37.774.    Discriminator Loss: 0.426.\n",
      "  Batch 1,800  of  25,622.    Elapsed: 0:25:30.    Generator Loss: 37.747.    Discriminator Loss: 0.428.\n",
      "  Batch 2,000  of  25,622.    Elapsed: 0:28:16.    Generator Loss: 37.744.    Discriminator Loss: 0.425.\n",
      "  Batch 2,200  of  25,622.    Elapsed: 0:31:01.    Generator Loss: 37.709.    Discriminator Loss: 0.420.\n",
      "  Batch 2,400  of  25,622.    Elapsed: 0:33:48.    Generator Loss: 37.709.    Discriminator Loss: 0.415.\n",
      "  Batch 2,600  of  25,622.    Elapsed: 0:36:35.    Generator Loss: 37.077.    Discriminator Loss: 0.573.\n",
      "  Batch 2,800  of  25,622.    Elapsed: 0:39:20.    Generator Loss: 35.639.    Discriminator Loss: 0.604.\n",
      "  Batch 3,000  of  25,622.    Elapsed: 0:42:02.    Generator Loss: 35.207.    Discriminator Loss: 0.586.\n",
      "  Batch 3,200  of  25,622.    Elapsed: 0:44:47.    Generator Loss: 35.045.    Discriminator Loss: 0.571.\n",
      "  Batch 3,400  of  25,622.    Elapsed: 0:47:33.    Generator Loss: 34.965.    Discriminator Loss: 0.605.\n",
      "  Batch 3,600  of  25,622.    Elapsed: 0:50:17.    Generator Loss: 34.749.    Discriminator Loss: 0.620.\n",
      "  Batch 3,800  of  25,622.    Elapsed: 0:53:03.    Generator Loss: 34.586.    Discriminator Loss: 0.611.\n",
      "  Batch 4,000  of  25,622.    Elapsed: 0:55:49.    Generator Loss: 34.507.    Discriminator Loss: 0.617.\n",
      "  Batch 4,200  of  25,622.    Elapsed: 0:58:33.    Generator Loss: 34.294.    Discriminator Loss: 0.593.\n",
      "  Batch 4,400  of  25,622.    Elapsed: 1:01:20.    Generator Loss: 34.142.    Discriminator Loss: 0.572.\n",
      "  Batch 4,600  of  25,622.    Elapsed: 1:04:04.    Generator Loss: 34.045.    Discriminator Loss: 0.573.\n",
      "  Batch 4,800  of  25,622.    Elapsed: 1:06:50.    Generator Loss: 33.987.    Discriminator Loss: 0.579.\n",
      "  Batch 5,000  of  25,622.    Elapsed: 1:09:36.    Generator Loss: 33.863.    Discriminator Loss: 0.580.\n",
      "  Batch 5,200  of  25,622.    Elapsed: 1:12:24.    Generator Loss: 33.870.    Discriminator Loss: 0.587.\n",
      "  Batch 5,400  of  25,622.    Elapsed: 1:15:09.    Generator Loss: 33.825.    Discriminator Loss: 0.593.\n",
      "  Batch 5,600  of  25,622.    Elapsed: 1:17:56.    Generator Loss: 33.750.    Discriminator Loss: 0.597.\n",
      "  Batch 5,800  of  25,622.    Elapsed: 1:20:42.    Generator Loss: 33.774.    Discriminator Loss: 0.595.\n",
      "  Batch 6,000  of  25,622.    Elapsed: 1:23:29.    Generator Loss: 33.707.    Discriminator Loss: 0.607.\n",
      "  Batch 6,200  of  25,622.    Elapsed: 1:26:15.    Generator Loss: 33.674.    Discriminator Loss: 0.605.\n",
      "  Batch 6,400  of  25,622.    Elapsed: 1:29:02.    Generator Loss: 33.630.    Discriminator Loss: 0.604.\n",
      "  Batch 6,600  of  25,622.    Elapsed: 1:31:47.    Generator Loss: 33.593.    Discriminator Loss: 0.613.\n",
      "  Batch 6,800  of  25,622.    Elapsed: 1:34:32.    Generator Loss: 33.547.    Discriminator Loss: 0.616.\n",
      "  Batch 7,000  of  25,622.    Elapsed: 1:37:18.    Generator Loss: 33.483.    Discriminator Loss: 0.614.\n",
      "  Batch 7,200  of  25,622.    Elapsed: 1:40:03.    Generator Loss: 33.482.    Discriminator Loss: 0.615.\n",
      "  Batch 7,400  of  25,622.    Elapsed: 1:42:50.    Generator Loss: 33.486.    Discriminator Loss: 0.612.\n",
      "  Batch 7,600  of  25,622.    Elapsed: 1:45:38.    Generator Loss: 33.425.    Discriminator Loss: 0.611.\n",
      "  Batch 7,800  of  25,622.    Elapsed: 1:48:25.    Generator Loss: 33.370.    Discriminator Loss: 0.608.\n",
      "  Batch 8,000  of  25,622.    Elapsed: 1:51:11.    Generator Loss: 33.364.    Discriminator Loss: 0.608.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "total_t0 = time.time()\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    generator_train_loss = 0\n",
    "    discriminator_train_loss = 0\n",
    "\n",
    "    generator.train()\n",
    "    discriminator.train()\n",
    "    generator.zero_grad()\n",
    "    discriminator.zero_grad()\n",
    "    for step, batch in enumerate(dataloader):\n",
    "        #generator\n",
    "        generator_input = batch[0].to(device)\n",
    "        generator_labels = batch[1].to(device)\n",
    "        generator_mask = batch[2].to(device)\n",
    "        generator_original = batch[3].to(device)\n",
    "        \n",
    "        generator_loss, generator_scores = generator(generator_input, attention_mask=generator_mask, labels=generator_labels)\n",
    "        generator_loss = generator_loss.mean()\n",
    "        generator_train_loss += generator_loss.item()\n",
    "        generator_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(generator.parameters(), 1.0)\n",
    "        \n",
    "        #discriminator\n",
    "        discriminator_input = torch.where(generator_labels>=0, torch.argmax(generator_scores,dim=2), generator_original)\n",
    "        discriminator_labels = torch.where(discriminator_input==generator_original, \n",
    "                                           torch.zeros_like(generator_original), torch.ones_like(generator_original))\n",
    "        discriminator_mask = generator_mask\n",
    "        \n",
    "        \n",
    "        discriminator_loss, discriminator_scores = discriminator(discriminator_input, \n",
    "                                                    attention_mask=discriminator_mask, labels=discriminator_labels)\n",
    "        discriminator_loss = discriminator_loss.mean()\n",
    "        discriminator_train_loss += discriminator_loss.item()\n",
    "        discriminator_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(discriminator.parameters(), 1.0)\n",
    "        \n",
    "        if step % accum_multipler == 0 and (accum_multipler == 1 or step != 0):\n",
    "            generator_optimizer.step()\n",
    "            generator_scheduler.step()\n",
    "            discriminator_optimizer.step()\n",
    "            discriminator_scheduler.step()\n",
    "            generator.zero_grad()\n",
    "            discriminator.zero_grad()\n",
    "        \n",
    "        if step % 200 == 0 and not step == 0:\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.    Generator Loss: {:.3f}.    Discriminator Loss: {:.3f}.'\n",
    "                  .format(step, len(dataloader), elapsed, generator_train_loss/40, discriminator_train_loss/40))\n",
    "            generator_train_loss = 0\n",
    "            discriminator_train_loss = 0\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "  Batch 16,800  of  25,622.    Elapsed: 3:54:08.    Generator Loss: 24.918.    Discriminator Loss: 0.752.\\n\n",
    "  Batch 17,000  of  25,622.    Elapsed: 3:56:57.    Generator Loss: 24.956.    Discriminator Loss: 0.754.\\n\n",
    "  Batch 17,200  of  25,622.    Elapsed: 3:59:46.    Generator Loss: 24.981.    Discriminator Loss: 0.752.\\n\n",
    "  Batch 17,400  of  25,622.    Elapsed: 4:02:35.    Generator Loss: 24.905.    Discriminator Loss: 0.752.\\n\n",
    "  Batch 17,600  of  25,622.    Elapsed: 4:05:21.    Generator Loss: 24.907.    Discriminator Loss: 0.751.\\n\n",
    "  Batch 17,800  of  25,622.    Elapsed: 4:08:04.    Generator Loss: 24.870.    Discriminator Loss: 0.747.\\n\n",
    "  Batch 18,000  of  25,622.    Elapsed: 4:10:51.    Generator Loss: 24.880.    Discriminator Loss: 0.751.\\n\n",
    "  Batch 18,200  of  25,622.    Elapsed: 4:13:40.    Generator Loss: 24.884.    Discriminator Loss: 0.752.\\n\n",
    "  Batch 18,400  of  25,622.    Elapsed: 4:16:27.    Generator Loss: 24.838.    Discriminator Loss: 0.750.\\n\n",
    "  Batch 18,600  of  25,622.    Elapsed: 4:19:13.    Generator Loss: 24.805.    Discriminator Loss: 0.747.\\n\n",
    "  Batch 18,800  of  25,622.    Elapsed: 4:22:02.    Generator Loss: 24.842.    Discriminator Loss: 0.754.\\n\n",
    "  Batch 19,000  of  25,622.    Elapsed: 4:24:48.    Generator Loss: 24.837.    Discriminator Loss: 0.748.\\n\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(generator,'electra_small_generator.pth')\n",
    "torch.save(discriminator,'electra_small_discriminator.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1,  ..., 1, 1, 0],\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 1, 1, 1]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "for step, batch in enumerate(dataloader):\n",
    "    break\n",
    "    \n",
    "batch[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = torch.load('electra_small_discriminator.pth')\n",
    "discriminator.cuda()\n",
    "generator = torch.load('electra_small_generator.pth')\n",
    "generator.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    }
   ],
   "source": [
    "generator.eval()\n",
    "discriminator.eval()\n",
    "with torch.no_grad():\n",
    "    for step, batch in enumerate(dataloader):\n",
    "        generator_input = batch[0].to(device)\n",
    "        generator_labels = batch[1].to(device)\n",
    "        generator_mask = batch[2].to(device)\n",
    "        generator_original = batch[3].to(device)\n",
    "\n",
    "        generator_loss, generator_scores = generator(generator_input, attention_mask=generator_mask, labels=generator_labels)\n",
    "\n",
    "\n",
    "        #discriminator\n",
    "        discriminator_input = torch.where(generator_labels>=0, torch.argmax(generator_scores,dim=2), generator_original)\n",
    "        discriminator_labels = torch.where(discriminator_input==generator_original, \n",
    "                                           torch.zeros_like(generator_original), torch.ones_like(generator_original))\n",
    "        discriminator_mask = generator_mask\n",
    "        discriminator_loss, discriminator_scores = discriminator(discrimisnator_input, \n",
    "                                                    attention_mask=discriminator_mask, labels=discriminator_labels)\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6.6637, 6.1166, 6.7644, 7.4927, 6.7277, 6.4525, 6.4347, 5.8803],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from termcolor import colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] # 架 垃 圾 車 違 反 交 通 \u001b[31m##bb\u001b[0m \u001b[31m1923\u001b[0m 喎 , 執 行 \u001b[31m[MASK]\u001b[0m 拆 \u001b[31m[MASK]\u001b[0m 可 以 無 視 法 律 ? <nl> # 1 a : \u001b[31m[MASK]\u001b[0m 咁 小 學 雞 啦 😗 <nl> # \u001b[31m[MASK]\u001b[0m b : # \u001b[31m[MASK]\u001b[0m 🤡 off ， 破 壞 法 治 丫 嗎 \u001b[31m[MASK]\u001b[0m 架 車 唔 係 警 察 \u001b[31m[MASK]\u001b[0m 喎 ， \u001b[31m[MASK]\u001b[0m 咩 有 特 權 ？ 幫 警 察 就 有 特 權 ？ <nl> \u001b[31m##らに\u001b[0m \u001b[31m[MASK]\u001b[0m c : # 2 咩 拎 野 小 學 雞 你 跟 足 人 地 個 套 玩 \u001b[31m[MASK]\u001b[0m 係 \u001b[31m侚\u001b[0m \u001b[31m##1999\u001b[0m \u001b[31m桉\u001b[0m ? <nl> [SEP] \n",
      "\n",
      "[CLS] # 架 垃 圾 車 違 反 交 通 \u001b[31m規\u001b[0m \u001b[31m則\u001b[0m 喎 , 執 行 \u001b[31m清\u001b[0m 拆 \u001b[31m就\u001b[0m 可 以 無 視 法 律 ? <nl> # 1 a : \u001b[31m咪\u001b[0m 咁 小 學 雞 啦 😗 <nl> # \u001b[31m2\u001b[0m b : # \u001b[31m1\u001b[0m 🤡 off ， 破 壞 法 治 丫 嗎 \u001b[31m，\u001b[0m 架 車 唔 係 警 察 \u001b[31m架\u001b[0m 喎 ， \u001b[31m憑\u001b[0m 咩 有 特 權 ？ 幫 警 察 就 有 特 權 ？ <nl> \u001b[31m#\u001b[0m \u001b[31m3\u001b[0m c : # 2 咩 拎 野 小 學 雞 你 跟 足 人 地 個 套 玩 \u001b[31m就\u001b[0m 係 \u001b[31m小\u001b[0m \u001b[31m學\u001b[0m \u001b[31m雞\u001b[0m ? <nl> [SEP] "
     ]
    }
   ],
   "source": [
    "\n",
    "for id, label in zip(generator_input[0], generator_labels[0]):\n",
    "    if id == 0:\n",
    "        continue\n",
    "    token = tokenizer.id_to_token(id)\n",
    "    if label > 0:\n",
    "        token = colored(token,'red')\n",
    "    print(token, end=\" \")\n",
    "    \n",
    "print()\n",
    "print()\n",
    "\n",
    "for id, label in zip(generator_input[0], generator_labels[0]):\n",
    "    if id == 0:\n",
    "        continue\n",
    "    token = tokenizer.id_to_token(id)\n",
    "    if label > 0:\n",
    "        token = colored(tokenizer.id_to_token(label),'red')\n",
    "    print(token, end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] # 架 垃 圾 車 違 反 交 通 \u001b[31m係\u001b[0m \u001b[31m#\u001b[0m 喎 , 執 行 \u001b[31m#\u001b[0m 拆 \u001b[31m#\u001b[0m 可 以 無 視 法 律 ? <nl> # 1 a : \u001b[31m#\u001b[0m 咁 小 學 雞 啦 😗 <nl> # \u001b[31m#\u001b[0m b : # \u001b[31m#\u001b[0m 🤡 off ， 破 壞 法 治 丫 嗎 \u001b[31m#\u001b[0m 架 車 唔 係 警 察 \u001b[31m#\u001b[0m 喎 ， \u001b[31m#\u001b[0m 咩 有 特 權 ？ 幫 警 察 就 有 特 權 ？ <nl> # \u001b[31m#\u001b[0m c : # 2 咩 拎 野 小 學 雞 你 跟 足 人 地 個 套 玩 \u001b[31m#\u001b[0m 係 \u001b[31m#\u001b[0m \u001b[31m#\u001b[0m \u001b[31m#\u001b[0m ? <nl> [SEP] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from termcolor import colored\n",
    "\n",
    "for id, label in zip(discriminator_input[0], discriminator_labels[0]):\n",
    "    if id == 0:\n",
    "        continue\n",
    "    token = tokenizer.id_to_token(id)\n",
    "    if label > 0:\n",
    "        token = colored(token,'red')\n",
    "    print(token, end=\" \")\n",
    "print()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   40, 11948,  4160,  4145,  4451, 13918,  3281,  4882,  6236,  7232,\n",
       "        18180,  8172, 13287, 26257, 15006,  9942,  6938,  4160,  2473,  2353,\n",
       "         9978,  4145,  4161,  2684, 11145,  2888,  8946,  3429,  3379, 11840,\n",
       "         6948,  6349,  7796,  5730, 13287,  3290,  3429,  3379, 11840,  6948,\n",
       "         6349,  5450,  4149, 13918,  2520,  2518,  6207,  2888,  8946,  8887,\n",
       "         6906,  8887,  6906,  8391,  2874,  6222, 11851,  7051,  5457],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator_original[0][discriminator_labels[0] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discriminator_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertWordPieceTokenizer(vocab_file = 'tokenizer/vocab.txt')\n",
    "tokenizer.add_special_tokens([\"<nl>\"])\n",
    "tokenizer.enable_truncation(max_length=512)\n",
    "tokenizer.enable_padding(length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# 112 c : 請 廣 傳 唔 佔 等 auntie 餵 狗 ？ 等 等 等 政 府 明 拖 你 龍 和 道 告 急 ！ ！ 1 ， 沒 公 民 提 名 2 ， 不 下 台 3 ， 沒 普 選 4 ， 沒 公 開 約 實 完 全 沒 回 應 明 玩 9 你 班 愚 民 你 班 垃 圾 左 膠 咩 事 宜 家 唔 佔 士 氣 及 談 判 籌 碼 大 減 ！ 輸 龍 和 運 動 必 輸 ！ # 113 bi : # 112 無 錯 ， 學 聯 賣 港 ， 行 動 升 級 ！ 🔥 # 114 bj : 明 知 傾 唔 掂 都 傾 係 形 象 工 程 有 得 傾 都 衝 就 會 比 人 覺 得 你 無 誠 意 為 佔 而 佔 宜 家 同 捉 棋 一 樣 可 進 可 退 ！ # 115 bc : # 114 而 家 唔 係 幫 你 班 hihi 戴 光 環 呀 👋 傾 乜 呀 ？ 會 答 應 根 本 無 須 傾 # 116 bk : # 115 傾 係 無 用 傾 得 成 先 叫 停 我 地 唔 該 # 117 bl : 今 次 政 府 收 唔 到 科 因 為 活 動 而 家 變 成 市 民 自 發 就 算 佢 同 學 聯 傾 除 非 真 係 傾 到 d 乜 否 則 一 定 收 唔 到 科 # 118 bj :? _?? _??? i? _?? y? ζh? u? {? _? o? _???? n? |?? h?? o? a? l?? n? _?? _??? y? a? p? _? [ email protected ]??? i? i? i? h? i # 119 bm : 怯 就 輸 一 世! 添 華 道 + 龍 和 道 必 須 圍 城 斷 路! 請 問, 大 家 手 無 寸 鐵, 唔 衝 擊, 可 以 做 到 d 乜? 有! 就 係 圍 城, 包 圍 到 滴 水 不 溜, 斷 敵 軍 出 入, 逼 降! 呢 樣 已 經 係 最 和 平 可 以 做 到, 而 又 最 有 效 既 手 段! 你 見 警 方 大 陣 仗 佈 防 就 知, 包 圍 呢 招 係 work! 我 地 唔 出 手, 純 包 圍, 包 圍 到 滴 水 不 溜, 不 準 進 出, 佢 地 敢 再 出 防 暴 就 全 世 界 聲 討! 如 果 連 呢 樣 都 做 唔 到, 我 真 係'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(generator_original[1].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'flor 112 c : 請 廣 傳 唔 佔 等 auntie 餵 狗 ？ 等 等 等 政 府 明 拖 你 龍 和 道 告 急 ！ ！ 1 alle 沒 driveusc 提 名 dam ， 不 下 台 3 ， 沒 普 選 4 ， 沒 公 開 約 實 完 全 滌 脧 應 明 玩 9 你 班ⓖ 傜 你 班 垃 圾 左 膠 咩 事 宜 家 唔 flor nova 氣 及 談 判 dak 畄 大 減 ！ 輸 龍 和 durham 鎡 必 輸 ！ # 113 bi : # 112 無 錯 ， 學 聯 賣 港 ， 行 動 升 級 ！ 🔥 # 114 bj : 明 知 傾 唔 掂 都ⓖ 係 形 象 工 程 有 得 傾 都 衝 就 會 比 人 覺 得 你 無 誠 意 為 佔 而 점령 宜 家 同 捉 棋 一 樣ཙ bil 可 退 ！✰ 115 bc : # 114 neck 滌 唔 係 幫 你 班 hihi 戴 光 環 呀 👋 傾 乜 娇 ？ 齿 통 應 根 本 無 須 傾 # 116 bk : www 115 傾 係 無 用 cave 獫 成 先 叫 停 我 地 唔 該 # 117 bl : 今 次 政 府 收 唔 到 科 因 為 活 動 而 家 變 成 市 民 自 發 就 算 佢 同 damned 聯 傾 除 非 真 係 傾 到 d 乜 否 則 一 定 收 唔 到 科 # dozen bj :? _?? 翩?? recently i? _ 🥮? y? ζ ㄽ? u? 琲? _? o?베이? municip?? n? |?? brilliant?? o? a cruel l?? n? _?? _? 畄? y? a? p? _ rights [ email protected ]??? i? i? i? h? i # 119 bm : 怯 就 includes 一 世! 魁 2b 특징 + flor rights 交 必 須 圍 城 斷 路! 請 問 塬 大 家 手 無 寸 鐵, 唔💎 1894, 可 以 做 到 d 乜? 有! 就 係 圍 城, × 2020년 到 滴 水 不 溜, 斷 敵 軍 出 入, 逼 降! 呢 樣 已 經 係 最 和 平 可 以 做 到 しられた 👫 又 1894 有 效 既 躭 畄! 你 見 警 方 大 陣 仗 佈 防 就 rights, 包 圍 呢 招 係 work! durham 地 唔 出 手, 純 包 圍, 包 圍 到 滴 水 sideways peng flor 不 準 進 出, pleasant 地 敢 再 出 防 暴 就 全 世 界 聲 討! 如 果 連 呢 樣 都 做 唔 到のて 我 真 係'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(discriminator_input[1].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
